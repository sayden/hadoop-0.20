2014-04-16 21:47:13,152 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = asusnotebook/192.168.1.107
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.20.205.0
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.20-security-205 -r 1179940; compiled by 'hortonfo' on Fri Oct  7 06:26:14 UTC 2011
************************************************************/
2014-04-16 21:47:13,251 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-04-16 21:47:13,259 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2014-04-16 21:47:13,260 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-04-16 21:47:13,260 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: JobTracker metrics system started
2014-04-16 21:47:13,357 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source QueueMetrics,q=default registered.
2014-04-16 21:47:13,480 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2014-04-16 21:47:13,480 WARN org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Source name ugi already exists!
2014-04-16 21:47:13,481 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2014-04-16 21:47:13,487 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2014-04-16 21:47:13,487 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2014-04-16 21:47:13,487 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2014-04-16 21:47:13,488 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2014-04-16 21:47:13,495 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as MaC
2014-04-16 21:47:13,512 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2014-04-16 21:47:13,512 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort54311 registered.
2014-04-16 21:47:13,513 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort54311 registered.
2014-04-16 21:47:13,609 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-04-16 21:47:13,664 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-04-16 21:47:13,688 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-04-16 21:47:13,689 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2014-04-16 21:47:13,690 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2014-04-16 21:47:13,691 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2014-04-16 21:47:13,691 INFO org.mortbay.log: jetty-6.1.26
2014-04-16 21:47:14,137 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2014-04-16 21:47:14,142 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2014-04-16 21:47:14,143 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source JobTrackerMetrics registered.
2014-04-16 21:47:14,143 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 54311
2014-04-16 21:47:14,143 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2014-04-16 21:47:14,386 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2014-04-16 21:47:14,516 INFO org.apache.hadoop.mapred.JobHistory: Creating DONE folder at file:/var/hadoop/logs/history/done
2014-04-16 21:47:14,520 INFO org.apache.hadoop.mapred.JobTracker: History server being initialized in embedded mode
2014-04-16 21:47:14,523 INFO org.apache.hadoop.mapred.JobHistoryServer: Started job history server at: localhost:50030
2014-04-16 21:47:14,523 INFO org.apache.hadoop.mapred.JobTracker: Job History Server web address: localhost:50030
2014-04-16 21:47:14,527 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Completed job store is inactive
2014-04-16 21:47:14,713 INFO org.apache.hadoop.mapred.JobTracker: Refreshing hosts information
2014-04-16 21:47:14,734 INFO org.apache.hadoop.util.HostsFileReader: Setting the includes file to 
2014-04-16 21:47:14,734 INFO org.apache.hadoop.util.HostsFileReader: Setting the excludes file to 
2014-04-16 21:47:14,734 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2014-04-16 21:47:14,734 INFO org.apache.hadoop.mapred.JobTracker: Decommissioning 0 nodes
2014-04-16 21:47:14,739 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2014-04-16 21:47:14,741 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 54311: starting
2014-04-16 21:47:14,741 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 54311: starting
2014-04-16 21:47:14,742 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 54311: starting
2014-04-16 21:47:14,743 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 54311: starting
2014-04-16 21:47:14,743 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 54311: starting
2014-04-16 21:47:14,744 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 54311: starting
2014-04-16 21:47:14,744 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 54311: starting
2014-04-16 21:47:14,745 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 54311: starting
2014-04-16 21:47:14,745 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 54311: starting
2014-04-16 21:47:14,746 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 54311: starting
2014-04-16 21:47:14,746 INFO org.apache.hadoop.mapred.JobTracker: Starting RUNNING
2014-04-16 21:47:14,746 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 54311: starting
2014-04-16 21:47:15,890 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/asusnotebook
2014-04-16 21:47:15,892 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_asusnotebook:localhost/127.0.0.1:48155 to host asusnotebook
2014-04-16 21:48:17,864 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/raspbmc
2014-04-16 21:48:17,864 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_raspbmc:localhost/127.0.0.1:54703 to host raspbmc
2014-04-16 21:50:54,375 INFO org.apache.hadoop.mapred.JobInProgress: job_201404162147_0001: nMaps=12 nReduces=1 max=-1
2014-04-16 21:50:54,386 INFO org.apache.hadoop.mapred.JobTracker: Job job_201404162147_0001 added successfully for user 'MaC' to queue 'default'
2014-04-16 21:50:54,387 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201404162147_0001
2014-04-16 21:50:54,387 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201404162147_0001
2014-04-16 21:50:54,388 INFO org.apache.hadoop.mapred.AuditLogger: USER=MaC	IP=192.168.1.107	OPERATION=SUBMIT_JOB	TARGET=job_201404162147_0001	RESULT=SUCCESS
2014-04-16 21:50:54,768 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /var/hadoop/hdfs/mapred/system/job_201404162147_0001/jobToken
2014-04-16 21:50:54,807 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201404162147_0001 = 786575000. Number of splits = 12
2014-04-16 21:50:54,807 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0001_m_000000 has split on node:/default-rack/asusnotebook
2014-04-16 21:50:54,807 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0001_m_000001 has split on node:/default-rack/asusnotebook
2014-04-16 21:50:54,808 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0001_m_000002 has split on node:/default-rack/asusnotebook
2014-04-16 21:50:54,808 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0001_m_000003 has split on node:/default-rack/asusnotebook
2014-04-16 21:50:54,808 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0001_m_000004 has split on node:/default-rack/asusnotebook
2014-04-16 21:50:54,808 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0001_m_000005 has split on node:/default-rack/asusnotebook
2014-04-16 21:50:54,808 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0001_m_000006 has split on node:/default-rack/asusnotebook
2014-04-16 21:50:54,809 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0001_m_000007 has split on node:/default-rack/asusnotebook
2014-04-16 21:50:54,809 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0001_m_000008 has split on node:/default-rack/asusnotebook
2014-04-16 21:50:54,809 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0001_m_000009 has split on node:/default-rack/asusnotebook
2014-04-16 21:50:54,809 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0001_m_000010 has split on node:/default-rack/asusnotebook
2014-04-16 21:50:54,809 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0001_m_000011 has split on node:/default-rack/asusnotebook
2014-04-16 21:50:54,810 INFO org.apache.hadoop.mapred.JobInProgress: job_201404162147_0001 LOCALITY_WAIT_FACTOR=0.5
2014-04-16 21:50:54,811 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201404162147_0001 initialized successfully with 12 map tasks and 1 reduce tasks.
2014-04-16 21:50:55,164 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201404162147_0001_m_000013_0' to tip task_201404162147_0001_m_000013, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:51:01,199 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0001_m_000013_0' has completed task_201404162147_0001_m_000013 successfully.
2014-04-16 21:51:01,202 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0001_m_000000_0' to tip task_201404162147_0001_m_000000, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:51:01,203 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0001_m_000000
2014-04-16 21:51:01,203 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0001_m_000001_0' to tip task_201404162147_0001_m_000001, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:51:01,204 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0001_m_000001
2014-04-16 21:51:03,913 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0001_m_000002_0' to tip task_201404162147_0001_m_000002, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:51:03,913 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162147_0001_m_000002
2014-04-16 21:51:03,914 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0001_m_000003_0' to tip task_201404162147_0001_m_000003, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:51:03,914 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162147_0001_m_000003
2014-04-16 21:51:07,778 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0001_m_000002_0: Error initializing attempt_201404162147_0001_m_000002_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:51:07,779 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0001_m_000002_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:51:07,781 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0001_m_000003_0: Error initializing attempt_201404162147_0001_m_000003_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:51:07,781 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0001_m_000003_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:51:07,787 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0001_m_000004_0' to tip task_201404162147_0001_m_000004, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:51:07,788 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162147_0001_m_000004
2014-04-16 21:51:07,789 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0001_m_000005_0' to tip task_201404162147_0001_m_000005, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:51:07,789 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162147_0001_m_000005
2014-04-16 21:51:07,789 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_m_000002_0'
2014-04-16 21:51:07,789 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_m_000003_0'
2014-04-16 21:51:10,944 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0001_m_000004_0: Error initializing attempt_201404162147_0001_m_000004_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:51:10,945 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0001_m_000004_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:51:10,946 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0001_m_000005_0: Error initializing attempt_201404162147_0001_m_000005_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:51:10,946 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0001_m_000005_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:51:10,947 INFO org.apache.hadoop.mapred.JobInProgress: TaskTracker at 'raspbmc' turned 'flaky'
2014-04-16 21:51:10,948 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0001_m_000006_0' to tip task_201404162147_0001_m_000006, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:51:10,948 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162147_0001_m_000006
2014-04-16 21:51:10,948 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0001_m_000007_0' to tip task_201404162147_0001_m_000007, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:51:10,948 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162147_0001_m_000007
2014-04-16 21:51:10,949 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_m_000004_0'
2014-04-16 21:51:10,952 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_m_000005_0'
2014-04-16 21:51:14,070 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0001_m_000006_0: Error initializing attempt_201404162147_0001_m_000006_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:51:14,070 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0001_m_000006_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:51:14,071 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0001_m_000007_0: Error initializing attempt_201404162147_0001_m_000007_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:51:14,071 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0001_m_000007_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:51:14,072 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0001_m_000008_0' to tip task_201404162147_0001_m_000008, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:51:14,073 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162147_0001_m_000008
2014-04-16 21:51:14,073 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0001_m_000009_0' to tip task_201404162147_0001_m_000009, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:51:14,073 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162147_0001_m_000009
2014-04-16 21:51:14,073 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_m_000006_0'
2014-04-16 21:51:14,073 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_m_000007_0'
2014-04-16 21:51:17,167 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0001_m_000008_0: Error initializing attempt_201404162147_0001_m_000008_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:51:17,167 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0001_m_000008_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:51:17,168 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0001_m_000009_0: Error initializing attempt_201404162147_0001_m_000009_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:51:17,168 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0001_m_000009_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:51:17,169 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0001_m_000010_0' to tip task_201404162147_0001_m_000010, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:51:17,170 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162147_0001_m_000010
2014-04-16 21:51:17,170 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0001_m_000011_0' to tip task_201404162147_0001_m_000011, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:51:17,170 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162147_0001_m_000011
2014-04-16 21:51:17,170 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_m_000008_0'
2014-04-16 21:51:17,171 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_m_000009_0'
2014-04-16 21:51:20,287 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0001_m_000010_0: Error initializing attempt_201404162147_0001_m_000010_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:51:20,287 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0001_m_000010_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:51:20,288 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0001_m_000011_0: Error initializing attempt_201404162147_0001_m_000011_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:51:20,288 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0001_m_000011_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:51:20,290 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_m_000010_0'
2014-04-16 21:51:20,290 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_m_000011_0'
2014-04-16 21:51:31,262 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0001_m_000000_0' has completed task_201404162147_0001_m_000000 successfully.
2014-04-16 21:51:31,264 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162147_0001_m_000002
2014-04-16 21:51:31,264 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0001_m_000002_1' to tip task_201404162147_0001_m_000002, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:51:31,264 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0001_m_000002
2014-04-16 21:51:31,295 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201404162147_0001_r_000000_0' to tip task_201404162147_0001_r_000000, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:51:34,304 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0001_m_000001_0' has completed task_201404162147_0001_m_000001 successfully.
2014-04-16 21:51:34,306 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162147_0001_m_000003
2014-04-16 21:51:34,306 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0001_m_000003_1' to tip task_201404162147_0001_m_000003, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:51:34,306 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0001_m_000003
2014-04-16 21:52:01,344 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0001_m_000002_1' has completed task_201404162147_0001_m_000002 successfully.
2014-04-16 21:52:01,346 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162147_0001_m_000004
2014-04-16 21:52:01,347 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0001_m_000004_1' to tip task_201404162147_0001_m_000004, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:52:01,347 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0001_m_000004
2014-04-16 21:52:04,352 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0001_m_000003_1' has completed task_201404162147_0001_m_000003 successfully.
2014-04-16 21:52:04,354 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162147_0001_m_000005
2014-04-16 21:52:04,354 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0001_m_000005_1' to tip task_201404162147_0001_m_000005, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:52:04,354 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0001_m_000005
2014-04-16 21:52:07,183 INFO org.apache.hadoop.mapred.JobInProgress: job_201404162147_0002: nMaps=12 nReduces=1 max=-1
2014-04-16 21:52:07,184 INFO org.apache.hadoop.mapred.JobTracker: Job job_201404162147_0002 added successfully for user 'MaC' to queue 'default'
2014-04-16 21:52:07,184 INFO org.apache.hadoop.mapred.AuditLogger: USER=MaC	IP=192.168.1.107	OPERATION=SUBMIT_JOB	TARGET=job_201404162147_0002	RESULT=SUCCESS
2014-04-16 21:52:07,201 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201404162147_0002
2014-04-16 21:52:07,201 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201404162147_0002
2014-04-16 21:52:07,425 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /var/hadoop/hdfs/mapred/system/job_201404162147_0002/jobToken
2014-04-16 21:52:07,433 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201404162147_0002 = 786575000. Number of splits = 12
2014-04-16 21:52:07,433 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0002_m_000000 has split on node:/default-rack/asusnotebook
2014-04-16 21:52:07,434 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0002_m_000001 has split on node:/default-rack/asusnotebook
2014-04-16 21:52:07,434 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0002_m_000002 has split on node:/default-rack/asusnotebook
2014-04-16 21:52:07,434 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0002_m_000003 has split on node:/default-rack/asusnotebook
2014-04-16 21:52:07,434 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0002_m_000004 has split on node:/default-rack/asusnotebook
2014-04-16 21:52:07,434 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0002_m_000005 has split on node:/default-rack/asusnotebook
2014-04-16 21:52:07,435 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0002_m_000006 has split on node:/default-rack/asusnotebook
2014-04-16 21:52:07,435 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0002_m_000007 has split on node:/default-rack/asusnotebook
2014-04-16 21:52:07,435 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0002_m_000008 has split on node:/default-rack/asusnotebook
2014-04-16 21:52:07,435 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0002_m_000009 has split on node:/default-rack/asusnotebook
2014-04-16 21:52:07,435 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0002_m_000010 has split on node:/default-rack/asusnotebook
2014-04-16 21:52:07,435 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162147_0002_m_000011 has split on node:/default-rack/asusnotebook
2014-04-16 21:52:07,436 INFO org.apache.hadoop.mapred.JobInProgress: job_201404162147_0002 LOCALITY_WAIT_FACTOR=0.5
2014-04-16 21:52:07,436 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201404162147_0002 initialized successfully with 12 map tasks and 1 reduce tasks.
2014-04-16 21:52:09,365 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201404162147_0002_m_000013_0' to tip task_201404162147_0002_m_000013, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:52:12,449 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0002_m_000013_0: Error initializing attempt_201404162147_0002_m_000013_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:52:12,449 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0002_m_000013_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:52:12,451 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201404162147_0002_r_000002_0' to tip task_201404162147_0002_r_000002, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:52:12,451 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000013_0'
2014-04-16 21:52:17,408 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0002_r_000002_0: Error initializing attempt_201404162147_0002_r_000002_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:52:17,408 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0002_r_000002_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.ReduceTaskStatus.setFinishTime(ReduceTaskStatus.java:64)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:52:17,411 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_r_000002_0'
2014-04-16 21:52:19,382 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201404162147_0002_r_000002_1' to tip task_201404162147_0002_r_000002, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:52:25,390 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0002_r_000002_1' has completed task_201404162147_0002_r_000002 successfully.
2014-04-16 21:52:26,597 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000000_0' to tip task_201404162147_0002_m_000000, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:52:26,598 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162147_0002_m_000000
2014-04-16 21:52:26,598 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000001_0' to tip task_201404162147_0002_m_000001, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:52:26,598 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162147_0002_m_000001
2014-04-16 21:52:29,688 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0002_m_000000_0: Error initializing attempt_201404162147_0002_m_000000_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:52:29,689 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0002_m_000000_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:52:29,689 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0002_m_000001_0: Error initializing attempt_201404162147_0002_m_000001_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:52:29,690 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0002_m_000001_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:52:29,690 INFO org.apache.hadoop.mapred.JobInProgress: TaskTracker at 'raspbmc' turned 'flaky'
2014-04-16 21:52:29,691 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000002_0' to tip task_201404162147_0002_m_000002, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:52:29,691 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162147_0002_m_000002
2014-04-16 21:52:29,692 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000003_0' to tip task_201404162147_0002_m_000003, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:52:29,692 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162147_0002_m_000003
2014-04-16 21:52:29,692 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000000_0'
2014-04-16 21:52:29,692 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000001_0'
2014-04-16 21:52:32,776 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0002_m_000002_0: Error initializing attempt_201404162147_0002_m_000002_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:52:32,777 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0002_m_000002_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:52:32,778 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0002_m_000003_0: Error initializing attempt_201404162147_0002_m_000003_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:52:32,778 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0002_m_000003_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:52:32,779 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000004_0' to tip task_201404162147_0002_m_000004, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:52:32,780 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162147_0002_m_000004
2014-04-16 21:52:32,780 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000005_0' to tip task_201404162147_0002_m_000005, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:52:32,780 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162147_0002_m_000005
2014-04-16 21:52:32,780 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000002_0'
2014-04-16 21:52:32,780 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000003_0'
2014-04-16 21:52:34,403 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0001_m_000004_1' has completed task_201404162147_0001_m_000004 successfully.
2014-04-16 21:52:34,405 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0001_m_000005_1' has completed task_201404162147_0001_m_000005 successfully.
2014-04-16 21:52:34,406 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162147_0001_m_000006
2014-04-16 21:52:34,406 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0001_m_000006_1' to tip task_201404162147_0001_m_000006, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:52:34,406 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0001_m_000006
2014-04-16 21:52:34,406 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162147_0001_m_000007
2014-04-16 21:52:34,407 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0001_m_000007_1' to tip task_201404162147_0001_m_000007, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:52:34,407 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0001_m_000007
2014-04-16 21:52:35,876 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0002_m_000004_0: Error initializing attempt_201404162147_0002_m_000004_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.GeneratedConstructorAccessor7.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:52:35,876 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0002_m_000004_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:52:35,877 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0002_m_000005_0: Error initializing attempt_201404162147_0002_m_000005_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.GeneratedConstructorAccessor7.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:52:35,877 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0002_m_000005_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:52:35,878 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000006_0' to tip task_201404162147_0002_m_000006, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:52:35,878 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162147_0002_m_000006
2014-04-16 21:52:35,878 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000007_0' to tip task_201404162147_0002_m_000007, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:52:35,878 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162147_0002_m_000007
2014-04-16 21:52:35,878 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000004_0'
2014-04-16 21:52:35,878 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000005_0'
2014-04-16 21:52:39,003 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0002_m_000006_0: Error initializing attempt_201404162147_0002_m_000006_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.GeneratedConstructorAccessor7.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:52:39,003 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0002_m_000006_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:52:39,004 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0002_m_000007_0: Error initializing attempt_201404162147_0002_m_000007_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.GeneratedConstructorAccessor7.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:52:39,005 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0002_m_000007_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:52:39,007 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000008_0' to tip task_201404162147_0002_m_000008, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:52:39,007 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162147_0002_m_000008
2014-04-16 21:52:39,007 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000009_0' to tip task_201404162147_0002_m_000009, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:52:39,007 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162147_0002_m_000009
2014-04-16 21:52:39,008 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000006_0'
2014-04-16 21:52:39,008 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000007_0'
2014-04-16 21:52:42,093 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0002_m_000008_0: Error initializing attempt_201404162147_0002_m_000008_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.GeneratedConstructorAccessor7.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:52:42,094 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0002_m_000008_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:52:42,095 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0002_m_000009_0: Error initializing attempt_201404162147_0002_m_000009_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.GeneratedConstructorAccessor7.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:52:42,095 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0002_m_000009_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:52:42,096 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000010_0' to tip task_201404162147_0002_m_000010, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:52:42,097 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162147_0002_m_000010
2014-04-16 21:52:42,097 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000011_0' to tip task_201404162147_0002_m_000011, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54703'
2014-04-16 21:52:42,097 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162147_0002_m_000011
2014-04-16 21:52:42,097 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000008_0'
2014-04-16 21:52:42,098 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000009_0'
2014-04-16 21:52:45,182 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0002_m_000010_0: Error initializing attempt_201404162147_0002_m_000010_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.GeneratedConstructorAccessor7.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:52:45,183 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0002_m_000010_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:52:45,183 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162147_0002_m_000011_0: Error initializing attempt_201404162147_0002_m_000011_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.GeneratedConstructorAccessor7.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 21:52:45,184 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162147_0002_m_000011_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 21:52:45,185 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000010_0'
2014-04-16 21:52:45,185 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000011_0'
2014-04-16 21:53:10,456 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0001_m_000006_1' has completed task_201404162147_0001_m_000006 successfully.
2014-04-16 21:53:10,458 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0001_m_000007_1' has completed task_201404162147_0001_m_000007 successfully.
2014-04-16 21:53:10,463 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162147_0001_m_000008
2014-04-16 21:53:10,464 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0001_m_000008_1' to tip task_201404162147_0001_m_000008, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:53:10,464 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0001_m_000008
2014-04-16 21:53:10,464 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162147_0001_m_000009
2014-04-16 21:53:10,464 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0001_m_000009_1' to tip task_201404162147_0001_m_000009, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:53:10,464 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0001_m_000009
2014-04-16 21:53:40,519 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0001_m_000008_1' has completed task_201404162147_0001_m_000008 successfully.
2014-04-16 21:53:40,521 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0001_m_000009_1' has completed task_201404162147_0001_m_000009 successfully.
2014-04-16 21:53:40,522 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162147_0001_m_000010
2014-04-16 21:53:40,522 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0001_m_000010_1' to tip task_201404162147_0001_m_000010, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:53:40,522 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0001_m_000010
2014-04-16 21:53:40,522 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162147_0001_m_000011
2014-04-16 21:53:40,522 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0001_m_000011_1' to tip task_201404162147_0001_m_000011, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:53:40,523 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0001_m_000011
2014-04-16 21:54:04,555 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0001_m_000011_1' has completed task_201404162147_0001_m_000011 successfully.
2014-04-16 21:54:04,557 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162147_0002_m_000000
2014-04-16 21:54:04,557 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000000_1' to tip task_201404162147_0002_m_000000, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:54:04,557 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0002_m_000000
2014-04-16 21:54:10,564 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0001_m_000010_1' has completed task_201404162147_0001_m_000010 successfully.
2014-04-16 21:54:10,572 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162147_0002_m_000001
2014-04-16 21:54:10,573 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000001_1' to tip task_201404162147_0002_m_000001, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:54:10,573 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0002_m_000001
2014-04-16 21:54:22,595 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0001_r_000000_0' has completed task_201404162147_0001_r_000000 successfully.
2014-04-16 21:54:22,601 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201404162147_0001_r_000001_0' to tip task_201404162147_0001_r_000001, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:54:28,610 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0001_r_000001_0' has completed task_201404162147_0001_r_000001 successfully.
2014-04-16 21:54:28,612 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201404162147_0001 has completed successfully.
2014-04-16 21:54:28,628 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201404162147_0001,submitTime=1397677854298,launchTime=1397677854810,firstMapTaskLaunchTime=1397677861202,firstReduceTaskLaunchTime=1397677891264,firstJobSetupTaskLaunchTime=1397677855142,firstJobCleanupTaskLaunchTime=1397678062600,finishTime=1397678068611,numMaps=12,numSlotsPerMap=1,numReduces=1,numSlotsPerReduce=1,user=MaC,queue=default,status=SUCCEEDED,mapSlotSeconds=364,reduceSlotsSeconds=174,clusterMapCapacity=4,clusterReduceCapacity=4
2014-04-16 21:54:28,720 INFO org.apache.hadoop.mapred.JobHistory: Creating DONE subfolder at file:/var/hadoop/logs/history/done/version-1/asusnotebook_1397677633556_/2014/04/16/000000
2014-04-16 21:54:28,722 INFO org.apache.hadoop.mapred.JobHistory: Moving file:/var/hadoop/logs/history/job_201404162147_0001_1397677854298_MaC_word+count to file:/var/hadoop/logs/history/done/version-1/asusnotebook_1397677633556_/2014/04/16/000000
2014-04-16 21:54:28,747 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_m_000000_0'
2014-04-16 21:54:28,749 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_m_000001_0'
2014-04-16 21:54:28,749 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_m_000002_1'
2014-04-16 21:54:28,749 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_m_000003_1'
2014-04-16 21:54:28,749 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_m_000004_1'
2014-04-16 21:54:28,749 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_m_000005_1'
2014-04-16 21:54:28,749 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_m_000006_1'
2014-04-16 21:54:28,749 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_m_000007_1'
2014-04-16 21:54:28,749 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_m_000008_1'
2014-04-16 21:54:28,749 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_m_000009_1'
2014-04-16 21:54:28,750 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_m_000010_1'
2014-04-16 21:54:28,750 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_m_000011_1'
2014-04-16 21:54:28,750 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_m_000013_0'
2014-04-16 21:54:28,750 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_r_000000_0'
2014-04-16 21:54:28,750 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0001_r_000001_0'
2014-04-16 21:54:28,797 INFO org.apache.hadoop.mapred.JobHistory: Moving file:/var/hadoop/logs/history/job_201404162147_0001_conf.xml to file:/var/hadoop/logs/history/done/version-1/asusnotebook_1397677633556_/2014/04/16/000000
2014-04-16 21:54:34,757 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0002_m_000000_1' has completed task_201404162147_0002_m_000000 successfully.
2014-04-16 21:54:34,758 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162147_0002_m_000002
2014-04-16 21:54:34,759 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000002_1' to tip task_201404162147_0002_m_000002, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:54:34,759 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0002_m_000002
2014-04-16 21:54:34,759 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201404162147_0002_r_000000_0' to tip task_201404162147_0002_r_000000, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:54:40,768 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0002_m_000001_1' has completed task_201404162147_0002_m_000001 successfully.
2014-04-16 21:54:40,770 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162147_0002_m_000003
2014-04-16 21:54:40,770 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000003_1' to tip task_201404162147_0002_m_000003, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:54:40,770 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0002_m_000003
2014-04-16 21:55:04,797 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0002_m_000002_1' has completed task_201404162147_0002_m_000002 successfully.
2014-04-16 21:55:04,798 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162147_0002_m_000004
2014-04-16 21:55:04,798 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000004_1' to tip task_201404162147_0002_m_000004, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:55:04,798 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0002_m_000004
2014-04-16 21:55:10,805 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0002_m_000003_1' has completed task_201404162147_0002_m_000003 successfully.
2014-04-16 21:55:10,810 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162147_0002_m_000005
2014-04-16 21:55:10,811 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000005_1' to tip task_201404162147_0002_m_000005, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:55:10,811 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0002_m_000005
2014-04-16 21:55:34,840 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0002_m_000004_1' has completed task_201404162147_0002_m_000004 successfully.
2014-04-16 21:55:34,841 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162147_0002_m_000006
2014-04-16 21:55:34,842 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000006_1' to tip task_201404162147_0002_m_000006, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:55:34,842 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0002_m_000006
2014-04-16 21:55:40,850 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0002_m_000005_1' has completed task_201404162147_0002_m_000005 successfully.
2014-04-16 21:55:40,852 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162147_0002_m_000007
2014-04-16 21:55:40,852 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000007_1' to tip task_201404162147_0002_m_000007, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:55:40,852 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0002_m_000007
2014-04-16 21:56:04,879 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0002_m_000006_1' has completed task_201404162147_0002_m_000006 successfully.
2014-04-16 21:56:04,880 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162147_0002_m_000008
2014-04-16 21:56:04,881 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000008_1' to tip task_201404162147_0002_m_000008, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:56:04,881 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0002_m_000008
2014-04-16 21:56:10,887 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0002_m_000007_1' has completed task_201404162147_0002_m_000007 successfully.
2014-04-16 21:56:10,889 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162147_0002_m_000009
2014-04-16 21:56:10,889 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000009_1' to tip task_201404162147_0002_m_000009, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:56:10,889 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0002_m_000009
2014-04-16 21:56:34,918 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0002_m_000008_1' has completed task_201404162147_0002_m_000008 successfully.
2014-04-16 21:56:34,919 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162147_0002_m_000010
2014-04-16 21:56:34,919 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000010_1' to tip task_201404162147_0002_m_000010, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:56:34,919 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0002_m_000010
2014-04-16 21:56:40,926 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0002_m_000009_1' has completed task_201404162147_0002_m_000009 successfully.
2014-04-16 21:56:58,944 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0002_m_000010_1' has completed task_201404162147_0002_m_000010 successfully.
2014-04-16 21:56:58,945 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162147_0002_m_000011
2014-04-16 21:56:58,945 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162147_0002_m_000011_1' to tip task_201404162147_0002_m_000011, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:56:58,946 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162147_0002_m_000011
2014-04-16 21:57:16,963 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0002_m_000011_1' has completed task_201404162147_0002_m_000011 successfully.
2014-04-16 21:57:31,980 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0002_r_000000_0' has completed task_201404162147_0002_r_000000 successfully.
2014-04-16 21:57:31,983 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201404162147_0002_m_000012_0' to tip task_201404162147_0002_m_000012, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:48155'
2014-04-16 21:57:37,989 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162147_0002_m_000012_0' has completed task_201404162147_0002_m_000012 successfully.
2014-04-16 21:57:37,990 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201404162147_0002 has completed successfully.
2014-04-16 21:57:37,990 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201404162147_0002,submitTime=1397677927115,launchTime=1397677927436,firstMapTaskLaunchTime=1397677946597,firstReduceTaskLaunchTime=1397678074759,firstJobSetupTaskLaunchTime=1397677929365,firstJobCleanupTaskLaunchTime=1397678251983,finishTime=1397678257990,numMaps=12,numSlotsPerMap=1,numReduces=1,numSlotsPerReduce=1,user=MaC,queue=default,status=SUCCEEDED,mapSlotSeconds=332,reduceSlotsSeconds=179,clusterMapCapacity=4,clusterReduceCapacity=4
2014-04-16 21:57:38,045 INFO org.apache.hadoop.mapred.JobHistory: Moving file:/var/hadoop/logs/history/job_201404162147_0002_1397677927115_MaC_word+count to file:/var/hadoop/logs/history/done/version-1/asusnotebook_1397677633556_/2014/04/16/000000
2014-04-16 21:57:38,046 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000000_1'
2014-04-16 21:57:38,046 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000001_1'
2014-04-16 21:57:38,046 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000002_1'
2014-04-16 21:57:38,046 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000003_1'
2014-04-16 21:57:38,046 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000004_1'
2014-04-16 21:57:38,046 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000005_1'
2014-04-16 21:57:38,047 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000006_1'
2014-04-16 21:57:38,047 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000007_1'
2014-04-16 21:57:38,047 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000008_1'
2014-04-16 21:57:38,047 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000009_1'
2014-04-16 21:57:38,047 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000010_1'
2014-04-16 21:57:38,047 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000011_1'
2014-04-16 21:57:38,047 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_m_000012_0'
2014-04-16 21:57:38,047 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_r_000000_0'
2014-04-16 21:57:38,047 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162147_0002_r_000002_1'
2014-04-16 21:57:38,155 INFO org.apache.hadoop.mapred.JobHistory: Moving file:/var/hadoop/logs/history/job_201404162147_0002_conf.xml to file:/var/hadoop/logs/history/done/version-1/asusnotebook_1397677633556_/2014/04/16/000000
2014-04-16 22:01:59,805 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at asusnotebook/192.168.1.107
************************************************************/
2014-04-16 22:02:20,168 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = asusnotebook/192.168.1.107
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.20.205.0
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.20-security-205 -r 1179940; compiled by 'hortonfo' on Fri Oct  7 06:26:14 UTC 2011
************************************************************/
2014-04-16 22:02:20,268 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-04-16 22:02:20,277 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2014-04-16 22:02:20,278 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-04-16 22:02:20,278 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: JobTracker metrics system started
2014-04-16 22:02:20,369 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source QueueMetrics,q=default registered.
2014-04-16 22:02:20,502 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2014-04-16 22:02:20,502 WARN org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Source name ugi already exists!
2014-04-16 22:02:20,504 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2014-04-16 22:02:20,506 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2014-04-16 22:02:20,507 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2014-04-16 22:02:20,516 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as MaC
2014-04-16 22:02:20,518 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2014-04-16 22:02:20,518 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2014-04-16 22:02:20,540 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort54311 registered.
2014-04-16 22:02:20,540 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort54311 registered.
2014-04-16 22:02:20,544 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2014-04-16 22:02:20,615 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-04-16 22:02:20,678 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-04-16 22:02:20,707 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2014-04-16 22:02:20,708 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2014-04-16 22:02:20,708 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2014-04-16 22:02:20,708 INFO org.mortbay.log: jetty-6.1.26
2014-04-16 22:02:21,169 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2014-04-16 22:02:21,174 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2014-04-16 22:02:21,175 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source JobTrackerMetrics registered.
2014-04-16 22:02:21,175 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 54311
2014-04-16 22:02:21,175 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2014-04-16 22:02:21,339 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2014-04-16 22:02:21,362 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://asusnotebook:54310/var/hadoop/hdfs/mapred/system
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /var/hadoop/hdfs/mapred/system. Name node is in safe mode.
The ratio of reported blocks 1,0000 has reached the threshold 0,9990. Safe mode will be turned off automatically in 26 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1967)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1947)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:781)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:710)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:251)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2410)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2192)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2186)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:300)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:291)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4978)
2014-04-16 22:02:31,369 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2014-04-16 22:02:31,370 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://asusnotebook:54310/var/hadoop/hdfs/mapred/system
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /var/hadoop/hdfs/mapred/system. Name node is in safe mode.
The ratio of reported blocks 1,0000 has reached the threshold 0,9990. Safe mode will be turned off automatically in 16 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1967)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1947)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:781)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:710)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:251)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2410)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2192)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2186)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:300)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:291)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4978)
2014-04-16 22:02:41,375 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2014-04-16 22:02:41,378 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://asusnotebook:54310/var/hadoop/hdfs/mapred/system
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /var/hadoop/hdfs/mapred/system. Name node is in safe mode.
The ratio of reported blocks 1,0000 has reached the threshold 0,9990. Safe mode will be turned off automatically in 6 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1967)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1947)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:781)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:710)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:251)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2410)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2192)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2186)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:300)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:291)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4978)
2014-04-16 22:02:51,384 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2014-04-16 22:02:51,566 INFO org.apache.hadoop.mapred.JobTracker: History server being initialized in embedded mode
2014-04-16 22:02:51,570 INFO org.apache.hadoop.mapred.JobHistoryServer: Started job history server at: localhost:50030
2014-04-16 22:02:51,570 INFO org.apache.hadoop.mapred.JobTracker: Job History Server web address: localhost:50030
2014-04-16 22:02:51,574 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Completed job store is inactive
2014-04-16 22:02:51,821 INFO org.apache.hadoop.mapred.JobTracker: Refreshing hosts information
2014-04-16 22:02:51,836 INFO org.apache.hadoop.util.HostsFileReader: Setting the includes file to 
2014-04-16 22:02:51,836 INFO org.apache.hadoop.util.HostsFileReader: Setting the excludes file to 
2014-04-16 22:02:51,836 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2014-04-16 22:02:51,836 INFO org.apache.hadoop.mapred.JobTracker: Decommissioning 0 nodes
2014-04-16 22:02:51,838 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2014-04-16 22:02:51,838 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 54311: starting
2014-04-16 22:02:51,847 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 54311: starting
2014-04-16 22:02:51,850 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 54311: starting
2014-04-16 22:02:51,851 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 54311: starting
2014-04-16 22:02:51,851 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 54311: starting
2014-04-16 22:02:51,851 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 54311: starting
2014-04-16 22:02:51,853 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 54311: starting
2014-04-16 22:02:51,854 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 54311: starting
2014-04-16 22:02:51,854 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 54311: starting
2014-04-16 22:02:51,855 INFO org.apache.hadoop.mapred.JobTracker: Starting RUNNING
2014-04-16 22:02:51,855 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 54311: starting
2014-04-16 22:02:51,856 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 54311: starting
2014-04-16 22:02:52,425 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/asusnotebook
2014-04-16 22:02:52,428 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_asusnotebook:localhost/127.0.0.1:50395 to host asusnotebook
2014-04-16 22:02:52,440 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-04-16 22:02:52,485 INFO org.apache.hadoop.mapred.JobInProgress: job_201404162202_0001: nMaps=12 nReduces=1 max=-1
2014-04-16 22:02:52,488 INFO org.apache.hadoop.mapred.JobTracker: Job job_201404162202_0001 added successfully for user 'MaC' to queue 'default'
2014-04-16 22:02:52,489 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201404162202_0001
2014-04-16 22:02:52,489 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201404162202_0001
2014-04-16 22:02:52,490 INFO org.apache.hadoop.mapred.AuditLogger: USER=MaC	IP=192.168.1.107	OPERATION=SUBMIT_JOB	TARGET=job_201404162202_0001	RESULT=SUCCESS
2014-04-16 22:02:52,708 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /var/hadoop/hdfs/mapred/system/job_201404162202_0001/jobToken
2014-04-16 22:02:52,727 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201404162202_0001 = 786575000. Number of splits = 12
2014-04-16 22:02:52,727 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162202_0001_m_000000 has split on node:/default-rack/asusnotebook
2014-04-16 22:02:52,727 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162202_0001_m_000001 has split on node:/default-rack/asusnotebook
2014-04-16 22:02:52,727 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162202_0001_m_000002 has split on node:/default-rack/asusnotebook
2014-04-16 22:02:52,728 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162202_0001_m_000003 has split on node:/default-rack/asusnotebook
2014-04-16 22:02:52,728 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162202_0001_m_000004 has split on node:/default-rack/asusnotebook
2014-04-16 22:02:52,728 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162202_0001_m_000005 has split on node:/default-rack/asusnotebook
2014-04-16 22:02:52,728 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162202_0001_m_000006 has split on node:/default-rack/asusnotebook
2014-04-16 22:02:52,728 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162202_0001_m_000007 has split on node:/default-rack/asusnotebook
2014-04-16 22:02:52,728 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162202_0001_m_000008 has split on node:/default-rack/asusnotebook
2014-04-16 22:02:52,728 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162202_0001_m_000009 has split on node:/default-rack/asusnotebook
2014-04-16 22:02:52,729 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162202_0001_m_000010 has split on node:/default-rack/asusnotebook
2014-04-16 22:02:52,729 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162202_0001_m_000011 has split on node:/default-rack/asusnotebook
2014-04-16 22:02:52,729 INFO org.apache.hadoop.mapred.JobInProgress: job_201404162202_0001 LOCALITY_WAIT_FACTOR=1.0
2014-04-16 22:02:52,730 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201404162202_0001 initialized successfully with 12 map tasks and 1 reduce tasks.
2014-04-16 22:02:55,452 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201404162202_0001_m_000013_0' to tip task_201404162202_0001_m_000013, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:50395'
2014-04-16 22:03:01,488 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162202_0001_m_000013_0' has completed task_201404162202_0001_m_000013 successfully.
2014-04-16 22:03:01,492 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162202_0001_m_000000_0' to tip task_201404162202_0001_m_000000, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:50395'
2014-04-16 22:03:01,492 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162202_0001_m_000000
2014-04-16 22:03:01,492 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162202_0001_m_000001_0' to tip task_201404162202_0001_m_000001, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:50395'
2014-04-16 22:03:01,493 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162202_0001_m_000001
2014-04-16 22:03:26,606 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/raspbmc
2014-04-16 22:03:26,606 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_raspbmc:localhost/127.0.0.1:54287 to host raspbmc
2014-04-16 22:03:26,607 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162202_0001_m_000002_0' to tip task_201404162202_0001_m_000002, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54287'
2014-04-16 22:03:26,607 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162202_0001_m_000002
2014-04-16 22:03:26,608 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162202_0001_m_000003_0' to tip task_201404162202_0001_m_000003, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54287'
2014-04-16 22:03:26,608 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162202_0001_m_000003
2014-04-16 22:03:30,438 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162202_0001_m_000002_0: Error initializing attempt_201404162202_0001_m_000002_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 22:03:30,439 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162202_0001_m_000002_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 22:03:30,441 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162202_0001_m_000003_0: Error initializing attempt_201404162202_0001_m_000003_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 22:03:30,442 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162202_0001_m_000003_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 22:03:30,444 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162202_0001_m_000004_0' to tip task_201404162202_0001_m_000004, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54287'
2014-04-16 22:03:30,444 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162202_0001_m_000004
2014-04-16 22:03:30,445 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162202_0001_m_000005_0' to tip task_201404162202_0001_m_000005, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54287'
2014-04-16 22:03:30,445 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162202_0001_m_000005
2014-04-16 22:03:30,445 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000002_0'
2014-04-16 22:03:30,445 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000003_0'
2014-04-16 22:03:31,554 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162202_0001_m_000000_0' has completed task_201404162202_0001_m_000000 successfully.
2014-04-16 22:03:31,556 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162202_0001_m_000001_0' has completed task_201404162202_0001_m_000001 successfully.
2014-04-16 22:03:31,557 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162202_0001_m_000002
2014-04-16 22:03:31,557 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162202_0001_m_000002_1' to tip task_201404162202_0001_m_000002, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:50395'
2014-04-16 22:03:31,558 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162202_0001_m_000002
2014-04-16 22:03:31,558 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162202_0001_m_000003
2014-04-16 22:03:31,558 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162202_0001_m_000003_1' to tip task_201404162202_0001_m_000003, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:50395'
2014-04-16 22:03:31,558 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162202_0001_m_000003
2014-04-16 22:03:31,562 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201404162202_0001_r_000000_0' to tip task_201404162202_0001_r_000000, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:50395'
2014-04-16 22:03:33,540 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162202_0001_m_000004_0: Error initializing attempt_201404162202_0001_m_000004_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 22:03:33,541 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162202_0001_m_000004_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 22:03:33,542 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162202_0001_m_000005_0: Error initializing attempt_201404162202_0001_m_000005_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 22:03:33,543 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162202_0001_m_000005_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 22:03:33,543 INFO org.apache.hadoop.mapred.JobInProgress: TaskTracker at 'raspbmc' turned 'flaky'
2014-04-16 22:03:33,544 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162202_0001_m_000006_0' to tip task_201404162202_0001_m_000006, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54287'
2014-04-16 22:03:33,544 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162202_0001_m_000006
2014-04-16 22:03:33,545 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162202_0001_m_000007_0' to tip task_201404162202_0001_m_000007, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54287'
2014-04-16 22:03:33,545 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162202_0001_m_000007
2014-04-16 22:03:33,545 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000004_0'
2014-04-16 22:03:33,545 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000005_0'
2014-04-16 22:03:36,682 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162202_0001_m_000006_0: Error initializing attempt_201404162202_0001_m_000006_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 22:03:36,683 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162202_0001_m_000006_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 22:03:36,684 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162202_0001_m_000007_0: Error initializing attempt_201404162202_0001_m_000007_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 22:03:36,684 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162202_0001_m_000007_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 22:03:36,685 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162202_0001_m_000008_0' to tip task_201404162202_0001_m_000008, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54287'
2014-04-16 22:03:36,685 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162202_0001_m_000008
2014-04-16 22:03:36,685 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162202_0001_m_000009_0' to tip task_201404162202_0001_m_000009, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54287'
2014-04-16 22:03:36,686 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162202_0001_m_000009
2014-04-16 22:03:36,686 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000006_0'
2014-04-16 22:03:36,686 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000007_0'
2014-04-16 22:03:39,782 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162202_0001_m_000008_0: Error initializing attempt_201404162202_0001_m_000008_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 22:03:39,783 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162202_0001_m_000008_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 22:03:39,784 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162202_0001_m_000009_0: Error initializing attempt_201404162202_0001_m_000009_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 22:03:39,784 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162202_0001_m_000009_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 22:03:39,785 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162202_0001_m_000010_0' to tip task_201404162202_0001_m_000010, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54287'
2014-04-16 22:03:39,785 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162202_0001_m_000010
2014-04-16 22:03:39,786 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162202_0001_m_000011_0' to tip task_201404162202_0001_m_000011, for tracker 'tracker_raspbmc:localhost/127.0.0.1:54287'
2014-04-16 22:03:39,786 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162202_0001_m_000011
2014-04-16 22:03:39,786 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000008_0'
2014-04-16 22:03:39,786 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000009_0'
2014-04-16 22:03:42,879 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162202_0001_m_000010_0: Error initializing attempt_201404162202_0001_m_000010_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 22:03:42,880 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162202_0001_m_000010_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 22:03:42,880 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162202_0001_m_000011_0: Error initializing attempt_201404162202_0001_m_000011_0:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:759)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:530)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:4229)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1150)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1091)
	at org.apache.hadoop.mapred.TaskTracker$5.run(TaskTracker.java:2360)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=pi, access=EXECUTE, inode="system":MaC:supergroup:rwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:155)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:125)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5164)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:5143)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1992)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:837)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at sun.proxy.$Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:757)
	... 6 more

2014-04-16 22:03:42,881 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201404162202_0001_m_000011_0 when no start time is set, stackTrace is : java.lang.Exception
	at org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:145)
	at org.apache.hadoop.mapred.TaskInProgress.incompleteSubTask(TaskInProgress.java:670)
	at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2942)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1159)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4739)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3683)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3378)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

2014-04-16 22:03:42,882 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000010_0'
2014-04-16 22:03:42,882 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000011_0'
2014-04-16 22:04:04,626 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162202_0001_m_000002_1' has completed task_201404162202_0001_m_000002 successfully.
2014-04-16 22:04:04,628 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162202_0001_m_000003_1' has completed task_201404162202_0001_m_000003 successfully.
2014-04-16 22:04:04,629 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162202_0001_m_000004
2014-04-16 22:04:04,630 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162202_0001_m_000004_1' to tip task_201404162202_0001_m_000004, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:50395'
2014-04-16 22:04:04,630 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162202_0001_m_000004
2014-04-16 22:04:04,630 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162202_0001_m_000005
2014-04-16 22:04:04,630 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162202_0001_m_000005_1' to tip task_201404162202_0001_m_000005, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:50395'
2014-04-16 22:04:04,630 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162202_0001_m_000005
2014-04-16 22:04:43,696 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162202_0001_m_000004_1' has completed task_201404162202_0001_m_000004 successfully.
2014-04-16 22:04:43,698 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162202_0001_m_000005_1' has completed task_201404162202_0001_m_000005 successfully.
2014-04-16 22:04:43,699 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162202_0001_m_000006
2014-04-16 22:04:43,699 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162202_0001_m_000006_1' to tip task_201404162202_0001_m_000006, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:50395'
2014-04-16 22:04:43,699 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162202_0001_m_000006
2014-04-16 22:04:43,700 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162202_0001_m_000007
2014-04-16 22:04:43,700 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162202_0001_m_000007_1' to tip task_201404162202_0001_m_000007, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:50395'
2014-04-16 22:04:43,700 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162202_0001_m_000007
2014-04-16 22:05:13,746 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162202_0001_m_000006_1' has completed task_201404162202_0001_m_000006 successfully.
2014-04-16 22:05:13,748 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162202_0001_m_000007_1' has completed task_201404162202_0001_m_000007 successfully.
2014-04-16 22:05:13,767 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162202_0001_m_000008
2014-04-16 22:05:13,768 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162202_0001_m_000008_1' to tip task_201404162202_0001_m_000008, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:50395'
2014-04-16 22:05:13,768 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162202_0001_m_000008
2014-04-16 22:05:13,768 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162202_0001_m_000009
2014-04-16 22:05:13,768 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162202_0001_m_000009_1' to tip task_201404162202_0001_m_000009, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:50395'
2014-04-16 22:05:13,768 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162202_0001_m_000009
2014-04-16 22:05:43,828 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162202_0001_m_000008_1' has completed task_201404162202_0001_m_000008 successfully.
2014-04-16 22:05:43,829 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162202_0001_m_000009_1' has completed task_201404162202_0001_m_000009 successfully.
2014-04-16 22:05:43,830 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162202_0001_m_000010
2014-04-16 22:05:43,831 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162202_0001_m_000010_1' to tip task_201404162202_0001_m_000010, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:50395'
2014-04-16 22:05:43,831 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162202_0001_m_000010
2014-04-16 22:06:10,863 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162202_0001_m_000010_1' has completed task_201404162202_0001_m_000010 successfully.
2014-04-16 22:06:10,865 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162202_0001_m_000011
2014-04-16 22:06:10,866 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162202_0001_m_000011_1' to tip task_201404162202_0001_m_000011, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:50395'
2014-04-16 22:06:10,866 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162202_0001_m_000011
2014-04-16 22:06:11,838 INFO org.apache.hadoop.mapred.JobTracker: attempt_201404162202_0001_m_000011_1 is 972 ms debug.
2014-04-16 22:06:28,886 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162202_0001_m_000011_1' has completed task_201404162202_0001_m_000011 successfully.
2014-04-16 22:06:40,903 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162202_0001_r_000000_0' has completed task_201404162202_0001_r_000000 successfully.
2014-04-16 22:06:40,909 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201404162202_0001_m_000012_0' to tip task_201404162202_0001_m_000012, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:50395'
2014-04-16 22:06:46,916 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162202_0001_m_000012_0' has completed task_201404162202_0001_m_000012 successfully.
2014-04-16 22:06:46,916 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201404162202_0001 has completed successfully.
2014-04-16 22:06:46,918 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201404162202_0001,submitTime=1397678572410,launchTime=1397678572729,firstMapTaskLaunchTime=1397678581491,firstReduceTaskLaunchTime=1397678611558,firstJobSetupTaskLaunchTime=1397678575437,firstJobCleanupTaskLaunchTime=1397678800909,finishTime=1397678806916,numMaps=12,numSlotsPerMap=1,numReduces=1,numSlotsPerReduce=1,user=MaC,queue=default,status=SUCCEEDED,mapSlotSeconds=366,reduceSlotsSeconds=187,clusterMapCapacity=4,clusterReduceCapacity=4
2014-04-16 22:06:46,945 INFO org.apache.hadoop.mapred.JobHistory: Creating DONE subfolder at file:/var/hadoop/logs/history/done/version-1/asusnotebook_1397678540577_/2014/04/16/000000
2014-04-16 22:06:46,947 INFO org.apache.hadoop.mapred.JobHistory: Moving file:/var/hadoop/logs/history/job_201404162202_0001_1397678572410_MaC_word+count to file:/var/hadoop/logs/history/done/version-1/asusnotebook_1397678540577_/2014/04/16/000000
2014-04-16 22:06:46,952 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000000_0'
2014-04-16 22:06:46,953 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000001_0'
2014-04-16 22:06:46,953 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000002_1'
2014-04-16 22:06:46,953 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000003_1'
2014-04-16 22:06:46,953 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000004_1'
2014-04-16 22:06:46,953 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000005_1'
2014-04-16 22:06:46,953 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000006_1'
2014-04-16 22:06:46,954 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000007_1'
2014-04-16 22:06:46,954 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000008_1'
2014-04-16 22:06:46,954 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000009_1'
2014-04-16 22:06:46,954 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000010_1'
2014-04-16 22:06:46,954 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000011_1'
2014-04-16 22:06:46,954 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000012_0'
2014-04-16 22:06:46,954 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_m_000013_0'
2014-04-16 22:06:46,954 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162202_0001_r_000000_0'
2014-04-16 22:06:47,008 INFO org.apache.hadoop.mapred.JobHistory: Moving file:/var/hadoop/logs/history/job_201404162202_0001_conf.xml to file:/var/hadoop/logs/history/done/version-1/asusnotebook_1397678540577_/2014/04/16/000000
2014-04-16 22:07:30,539 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at asusnotebook/192.168.1.107
************************************************************/
2014-04-16 22:08:08,222 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = asusnotebook/192.168.1.107
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.20.205.0
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.20-security-205 -r 1179940; compiled by 'hortonfo' on Fri Oct  7 06:26:14 UTC 2011
************************************************************/
2014-04-16 22:08:08,324 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-04-16 22:08:08,333 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2014-04-16 22:08:08,334 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-04-16 22:08:08,334 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: JobTracker metrics system started
2014-04-16 22:08:08,439 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source QueueMetrics,q=default registered.
2014-04-16 22:08:08,526 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2014-04-16 22:08:08,527 WARN org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Source name ugi already exists!
2014-04-16 22:08:08,528 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2014-04-16 22:08:08,529 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2014-04-16 22:08:08,529 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2014-04-16 22:08:08,529 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2014-04-16 22:08:08,530 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2014-04-16 22:08:08,537 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as MaC
2014-04-16 22:08:08,558 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort54311 registered.
2014-04-16 22:08:08,558 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort54311 registered.
2014-04-16 22:08:08,562 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2014-04-16 22:08:08,653 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-04-16 22:08:08,716 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-04-16 22:08:08,755 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2014-04-16 22:08:08,757 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2014-04-16 22:08:08,757 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2014-04-16 22:08:08,757 INFO org.mortbay.log: jetty-6.1.26
2014-04-16 22:08:09,194 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2014-04-16 22:08:09,201 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2014-04-16 22:08:09,202 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source JobTrackerMetrics registered.
2014-04-16 22:08:09,202 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 54311
2014-04-16 22:08:09,203 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2014-04-16 22:08:09,392 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2014-04-16 22:08:09,416 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://asusnotebook:54310/var/hadoop/hdfs/mapred/system
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /var/hadoop/hdfs/mapred/system. Name node is in safe mode.
The ratio of reported blocks 1,0000 has reached the threshold 0,9990. Safe mode will be turned off automatically in 25 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1967)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1947)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:781)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:710)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:251)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2410)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2192)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2186)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:300)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:291)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4978)
2014-04-16 22:08:19,421 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2014-04-16 22:08:19,423 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://asusnotebook:54310/var/hadoop/hdfs/mapred/system
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /var/hadoop/hdfs/mapred/system. Name node is in safe mode.
The ratio of reported blocks 1,0000 has reached the threshold 0,9990. Safe mode will be turned off automatically in 15 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1967)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1947)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:781)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:710)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:251)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2410)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2192)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2186)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:300)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:291)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4978)
2014-04-16 22:08:29,428 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2014-04-16 22:08:29,430 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://asusnotebook:54310/var/hadoop/hdfs/mapred/system
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /var/hadoop/hdfs/mapred/system. Name node is in safe mode.
The ratio of reported blocks 1,0000 has reached the threshold 0,9990. Safe mode will be turned off automatically in 5 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1967)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1947)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:781)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1066)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:710)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:251)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2410)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2192)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2186)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:300)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:291)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4978)
2014-04-16 22:08:39,435 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2014-04-16 22:08:39,567 INFO org.apache.hadoop.mapred.JobTracker: History server being initialized in embedded mode
2014-04-16 22:08:39,569 INFO org.apache.hadoop.mapred.JobHistoryServer: Started job history server at: localhost:50030
2014-04-16 22:08:39,570 INFO org.apache.hadoop.mapred.JobTracker: Job History Server web address: localhost:50030
2014-04-16 22:08:39,572 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Completed job store is inactive
2014-04-16 22:08:39,723 INFO org.apache.hadoop.mapred.JobTracker: Refreshing hosts information
2014-04-16 22:08:39,738 INFO org.apache.hadoop.util.HostsFileReader: Setting the includes file to 
2014-04-16 22:08:39,738 INFO org.apache.hadoop.util.HostsFileReader: Setting the excludes file to 
2014-04-16 22:08:39,738 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2014-04-16 22:08:39,738 INFO org.apache.hadoop.mapred.JobTracker: Decommissioning 0 nodes
2014-04-16 22:08:39,739 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2014-04-16 22:08:39,740 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 54311: starting
2014-04-16 22:08:39,740 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 54311: starting
2014-04-16 22:08:39,741 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 54311: starting
2014-04-16 22:08:39,741 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 54311: starting
2014-04-16 22:08:39,741 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 54311: starting
2014-04-16 22:08:39,741 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 54311: starting
2014-04-16 22:08:39,742 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 54311: starting
2014-04-16 22:08:39,742 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 54311: starting
2014-04-16 22:08:39,742 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 54311: starting
2014-04-16 22:08:39,742 INFO org.apache.hadoop.mapred.JobTracker: Starting RUNNING
2014-04-16 22:08:39,743 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 54311: starting
2014-04-16 22:08:39,743 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 54311: starting
2014-04-16 22:08:40,181 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/asusnotebook
2014-04-16 22:08:40,183 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_asusnotebook:localhost/127.0.0.1:33101 to host asusnotebook
2014-04-16 22:09:08,653 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/raspbmc
2014-04-16 22:09:08,653 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_raspbmc:localhost/127.0.0.1:41862 to host raspbmc
2014-04-16 22:09:17,955 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-04-16 22:09:17,997 INFO org.apache.hadoop.mapred.JobInProgress: job_201404162208_0001: nMaps=12 nReduces=1 max=-1
2014-04-16 22:09:17,999 INFO org.apache.hadoop.mapred.JobTracker: Job job_201404162208_0001 added successfully for user 'MaC' to queue 'default'
2014-04-16 22:09:18,000 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201404162208_0001
2014-04-16 22:09:18,000 INFO org.apache.hadoop.mapred.AuditLogger: USER=MaC	IP=192.168.1.107	OPERATION=SUBMIT_JOB	TARGET=job_201404162208_0001	RESULT=SUCCESS
2014-04-16 22:09:18,000 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201404162208_0001
2014-04-16 22:09:18,210 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /var/hadoop/hdfs/mapred/system/job_201404162208_0001/jobToken
2014-04-16 22:09:18,222 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201404162208_0001 = 786575000. Number of splits = 12
2014-04-16 22:09:18,223 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162208_0001_m_000000 has split on node:/default-rack/asusnotebook
2014-04-16 22:09:18,223 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162208_0001_m_000001 has split on node:/default-rack/asusnotebook
2014-04-16 22:09:18,223 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162208_0001_m_000002 has split on node:/default-rack/asusnotebook
2014-04-16 22:09:18,223 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162208_0001_m_000003 has split on node:/default-rack/asusnotebook
2014-04-16 22:09:18,223 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162208_0001_m_000004 has split on node:/default-rack/asusnotebook
2014-04-16 22:09:18,223 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162208_0001_m_000005 has split on node:/default-rack/asusnotebook
2014-04-16 22:09:18,223 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162208_0001_m_000006 has split on node:/default-rack/asusnotebook
2014-04-16 22:09:18,223 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162208_0001_m_000007 has split on node:/default-rack/asusnotebook
2014-04-16 22:09:18,224 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162208_0001_m_000008 has split on node:/default-rack/asusnotebook
2014-04-16 22:09:18,224 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162208_0001_m_000009 has split on node:/default-rack/asusnotebook
2014-04-16 22:09:18,224 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162208_0001_m_000010 has split on node:/default-rack/asusnotebook
2014-04-16 22:09:18,224 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201404162208_0001_m_000011 has split on node:/default-rack/asusnotebook
2014-04-16 22:09:18,224 INFO org.apache.hadoop.mapred.JobInProgress: job_201404162208_0001 LOCALITY_WAIT_FACTOR=0.5
2014-04-16 22:09:18,225 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201404162208_0001 initialized successfully with 12 map tasks and 1 reduce tasks.
2014-04-16 22:09:19,254 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201404162208_0001_m_000013_0' to tip task_201404162208_0001_m_000013, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:33101'
2014-04-16 22:09:25,288 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162208_0001_m_000013_0' has completed task_201404162208_0001_m_000013 successfully.
2014-04-16 22:09:25,292 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162208_0001_m_000000_0' to tip task_201404162208_0001_m_000000, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:33101'
2014-04-16 22:09:25,293 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162208_0001_m_000000
2014-04-16 22:09:25,293 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162208_0001_m_000001_0' to tip task_201404162208_0001_m_000001, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:33101'
2014-04-16 22:09:25,293 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162208_0001_m_000001
2014-04-16 22:09:27,120 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162208_0001_m_000002_0' to tip task_201404162208_0001_m_000002, for tracker 'tracker_raspbmc:localhost/127.0.0.1:41862'
2014-04-16 22:09:27,121 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162208_0001_m_000002
2014-04-16 22:09:27,122 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162208_0001_m_000003_0' to tip task_201404162208_0001_m_000003, for tracker 'tracker_raspbmc:localhost/127.0.0.1:41862'
2014-04-16 22:09:27,122 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201404162208_0001_m_000003
2014-04-16 22:09:58,358 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162208_0001_m_000000_0' has completed task_201404162208_0001_m_000000 successfully.
2014-04-16 22:09:58,362 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162208_0001_m_000001_0' has completed task_201404162208_0001_m_000001 successfully.
2014-04-16 22:09:58,364 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162208_0001_m_000004_0' to tip task_201404162208_0001_m_000004, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:33101'
2014-04-16 22:09:58,364 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162208_0001_m_000004
2014-04-16 22:09:58,364 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162208_0001_m_000005_0' to tip task_201404162208_0001_m_000005, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:33101'
2014-04-16 22:09:58,365 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162208_0001_m_000005
2014-04-16 22:09:58,369 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201404162208_0001_r_000000_0' to tip task_201404162208_0001_r_000000, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:33101'
2014-04-16 22:10:43,471 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162208_0001_m_000004_0' has completed task_201404162208_0001_m_000004 successfully.
2014-04-16 22:10:43,474 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162208_0001_m_000006_0' to tip task_201404162208_0001_m_000006, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:33101'
2014-04-16 22:10:43,474 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162208_0001_m_000006
2014-04-16 22:10:49,523 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162208_0001_m_000005_0' has completed task_201404162208_0001_m_000005 successfully.
2014-04-16 22:10:49,530 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162208_0001_m_000007_0' to tip task_201404162208_0001_m_000007, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:33101'
2014-04-16 22:10:49,530 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162208_0001_m_000007
2014-04-16 22:10:59,094 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201404162208_0001_m_000003_0: java.lang.Throwable: Child Error
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:271)
Caused by: java.io.IOException: Task process exit with nonzero status of 137.
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:258)

2014-04-16 22:11:02,367 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162208_0001_m_000003_0'
2014-04-16 22:11:02,367 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201404162208_0001_m_000003_0' to tip task_201404162208_0001_m_000003, for tracker 'tracker_raspbmc:localhost/127.0.0.1:41862'
2014-04-16 22:11:13,569 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162208_0001_m_000006_0' has completed task_201404162208_0001_m_000006 successfully.
2014-04-16 22:11:13,573 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162208_0001_m_000008_0' to tip task_201404162208_0001_m_000008, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:33101'
2014-04-16 22:11:13,574 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162208_0001_m_000008
2014-04-16 22:11:19,604 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162208_0001_m_000007_0' has completed task_201404162208_0001_m_000007 successfully.
2014-04-16 22:11:19,607 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162208_0001_m_000009_0' to tip task_201404162208_0001_m_000009, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:33101'
2014-04-16 22:11:19,607 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162208_0001_m_000009
2014-04-16 22:11:43,729 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162208_0001_m_000008_0' has completed task_201404162208_0001_m_000008 successfully.
2014-04-16 22:11:43,747 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162208_0001_m_000010_0' to tip task_201404162208_0001_m_000010, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:33101'
2014-04-16 22:11:43,748 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162208_0001_m_000010
2014-04-16 22:11:49,756 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162208_0001_m_000009_0' has completed task_201404162208_0001_m_000009 successfully.
2014-04-16 22:11:49,760 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162208_0001_m_000011_0' to tip task_201404162208_0001_m_000011, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:33101'
2014-04-16 22:11:49,760 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162208_0001_m_000011
2014-04-16 22:12:13,793 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162208_0001_m_000010_0' has completed task_201404162208_0001_m_000010 successfully.
2014-04-16 22:12:13,795 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162208_0001_m_000011_0' has completed task_201404162208_0001_m_000011 successfully.
2014-04-16 22:12:13,848 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162208_0001_m_000002_1' to tip task_201404162208_0001_m_000002, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:33101'
2014-04-16 22:12:13,848 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162208_0001_m_000002
2014-04-16 22:12:21,095 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162208_0001_m_000003_0'
2014-04-16 22:12:37,902 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162208_0001_m_000002_1' has completed task_201404162208_0001_m_000002 successfully.
2014-04-16 22:12:37,904 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a failed task task_201404162208_0001_m_000003
2014-04-16 22:12:37,904 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201404162208_0001_m_000003_1' to tip task_201404162208_0001_m_000003, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:33101'
2014-04-16 22:12:37,904 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201404162208_0001_m_000003
2014-04-16 22:12:43,258 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162208_0001_m_000002_0'
2014-04-16 22:12:43,258 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201404162208_0001_m_000002_0' to tip task_201404162208_0001_m_000002, for tracker 'tracker_raspbmc:localhost/127.0.0.1:41862'
2014-04-16 22:13:04,935 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162208_0001_m_000003_1' has completed task_201404162208_0001_m_000003 successfully.
2014-04-16 22:13:14,248 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162208_0001_r_000000_0' has completed task_201404162208_0001_r_000000 successfully.
2014-04-16 22:13:14,286 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201404162208_0001_m_000012_0' to tip task_201404162208_0001_m_000012, for tracker 'tracker_asusnotebook:localhost/127.0.0.1:33101'
2014-04-16 22:13:20,319 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201404162208_0001_m_000012_0' has completed task_201404162208_0001_m_000012 successfully.
2014-04-16 22:13:20,320 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201404162208_0001 has completed successfully.
2014-04-16 22:13:20,393 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201404162208_0001,submitTime=1397678957941,launchTime=1397678958224,firstMapTaskLaunchTime=1397678965292,firstReduceTaskLaunchTime=1397678998365,firstJobSetupTaskLaunchTime=1397678959240,firstJobCleanupTaskLaunchTime=1397679194285,finishTime=1397679200320,numMaps=12,numSlotsPerMap=1,numReduces=1,numSlotsPerReduce=1,user=MaC,queue=default,status=SUCCEEDED,mapSlotSeconds=454,reduceSlotsSeconds=193,clusterMapCapacity=4,clusterReduceCapacity=4
2014-04-16 22:13:20,479 INFO org.apache.hadoop.mapred.JobHistory: Creating DONE subfolder at file:/var/hadoop/logs/history/done/version-1/asusnotebook_1397678888607_/2014/04/16/000000
2014-04-16 22:13:20,481 INFO org.apache.hadoop.mapred.JobHistory: Moving file:/var/hadoop/logs/history/job_201404162208_0001_1397678957941_MaC_word+count to file:/var/hadoop/logs/history/done/version-1/asusnotebook_1397678888607_/2014/04/16/000000
2014-04-16 22:13:20,510 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162208_0001_m_000000_0'
2014-04-16 22:13:20,511 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162208_0001_m_000001_0'
2014-04-16 22:13:20,511 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162208_0001_m_000002_1'
2014-04-16 22:13:20,511 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162208_0001_m_000003_1'
2014-04-16 22:13:20,511 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162208_0001_m_000004_0'
2014-04-16 22:13:20,511 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162208_0001_m_000005_0'
2014-04-16 22:13:20,511 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162208_0001_m_000006_0'
2014-04-16 22:13:20,511 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162208_0001_m_000007_0'
2014-04-16 22:13:20,512 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162208_0001_m_000008_0'
2014-04-16 22:13:20,512 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162208_0001_m_000009_0'
2014-04-16 22:13:20,512 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162208_0001_m_000010_0'
2014-04-16 22:13:20,512 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162208_0001_m_000011_0'
2014-04-16 22:13:20,512 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162208_0001_m_000012_0'
2014-04-16 22:13:20,512 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162208_0001_m_000013_0'
2014-04-16 22:13:20,512 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162208_0001_r_000000_0'
2014-04-16 22:13:20,551 INFO org.apache.hadoop.mapred.JobHistory: Moving file:/var/hadoop/logs/history/job_201404162208_0001_conf.xml to file:/var/hadoop/logs/history/done/version-1/asusnotebook_1397678888607_/2014/04/16/000000
2014-04-16 22:13:22,907 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201404162208_0001_m_000002_0'
